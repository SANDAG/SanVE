{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "_join = os.path.join\n",
    "toolpath = os.getcwd()\n",
    "\n",
    "CONFIG = r'T:/ABM/ABM_FY21/Sketch_Planning/VisionEval/Model/Update_Automations/settings.yml'\n",
    "with open(CONFIG) as cff:\n",
    "    config =yaml.safe_load(cff)\n",
    "scenario_list = config['scenario_list']\n",
    "target_path = ''.join(config['target_path'])\n",
    "ComSvcPow = config['ComSvcPow']\n",
    "hvytrk_powertrain_prop = config['hvytrk_powertrain_prop']\n",
    "ComSvcLtTrkProp = config['ComSvcLtTrkProp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(\"DRIVER={SQL Server};\"\n",
    "                      \"SERVER=DDAMWSQL16;\"\n",
    "                      \"DATABASE=dpoe_stage;\" \n",
    "                      \"Trusted_Connection=yes;\")\n",
    "sql2 = (\"SELECT * FROM [dpoe_stage].[veh_reg_dmv].[fact] where yr=2017 and own = 'Commercial' and not make is null and not series is null\")\n",
    "df_sql2 = pd.read_sql_query(sql2, conn)\n",
    "df_sql2['make'] = df_sql2['make'].str.lower()\n",
    "df_sql2['series'] = df_sql2['series'].str.lower()\n",
    "df_sql2['category'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comm = pd.read_csv(_join(toolpath, 'dmv commercial vehicle class dataset-lookup.csv'))\n",
    "df_comm['make'] = df_comm['make'].str.lower()\n",
    "df_comm['series'] = df_comm['series'].str.lower()\n",
    "df_vehset = pd.read_csv(_join(toolpath, 'vehicle class dataset-lookup.csv'))\n",
    "df_vehset['Make'] = df_vehset['Make'].str.lower()\n",
    "df_vehset['Model'] = df_vehset['Model'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-202-9cfb5aad7185>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sql2['category'][ind] = df_select.loc[[item[2]]]['Category3'].to_list()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-202-9cfb5aad7185>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sql2['category'][ind] = df_commsel.loc[[item[2]]]['category'].to_list()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 20000\n",
      "processed 40000\n",
      "processed 60000\n",
      "processed 80000\n",
      "processed 100000\n",
      "processed 120000\n",
      "processed 140000\n",
      "processed 160000\n",
      "processed 180000\n",
      "processed 200000\n",
      "processed 220000\n",
      "processed 240000\n"
     ]
    }
   ],
   "source": [
    "counter = 20000\n",
    "df_dmvexcept = pd.DataFrame(columns=df_sql2.columns)\n",
    "for ind in df_sql2.index:\n",
    "    if ind < 100000000000000000000001:\n",
    "        df_select = df_vehset[df_vehset['Make'].str.contains(df_sql2['make'][ind])]\n",
    "        df_commsel = df_comm[df_comm['make'].str.contains(df_sql2['make'][ind])]        \n",
    "        if not df_select.empty:\n",
    "            #process.extractOne(df_sql2['series'][ind], df_select['Model'])           \n",
    "            try:\n",
    "                item = process.extractOne(df_sql2['series'][ind], df_select['Model'])\n",
    "                df_sql2['category'][ind] = df_select.loc[[item[2]]]['Category3'].to_list()[0]\n",
    "                #print ('a111', df_select.loc[[item[2]]]['Category3'].to_list()[0])\n",
    "            except:\n",
    "                print ('a222', df_sql2['model'][ind])\n",
    "        elif not df_commsel.empty:\n",
    "                #process.extractOne(df_sql2['series'][ind], df_commsel['series'])           \n",
    "            try:\n",
    "                item = process.extractOne(df_sql2['series'][ind],  df_commsel['series'])\n",
    "                df_sql2['category'][ind] = df_commsel.loc[[item[2]]]['category'].to_list()[0]\n",
    "                #print ('a333',  df_commsel.loc[[item[2]]]['category'].to_list()[0])\n",
    "            except:\n",
    "                print ('a444', df_sql2['model'][ind]) \n",
    "        else:\n",
    "            df_dmvexcept = df_dmvexcept.append(df_sql2.loc[[ind]])\n",
    "            print ('a555')\n",
    "        if ind % counter == 0:\n",
    "            print (\"processed\", ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fuel(x):\n",
    "    names = {\n",
    "        'Ice': x[(x['fuel_type']=='COMPRESSED NGASOLINE')|(x['fuel_type']=='DIESEL')|(x['fuel_type']=='FLEX METHANOL')|(x['fuel_type']=='GASOLINE')|(x['fuel_type']=='NATURAL GAS')|(x['fuel_type']=='PROPANE')|(x['fuel_type']=='HYDROGENATURAL GAS')]['count'].sum(),\n",
    "        'Hev': x[(x['fuel_type']=='FXELECTRIC')|(x['fuel_type']=='HGASOLINE')|(x['fuel_type']=='PHEV')]['count'].sum(),\n",
    "        'Bev': x[x['fuel_type']=='ELECTRIC']['count'].sum()}\n",
    "    return pd.Series(names)\n",
    "\n",
    "# region_comsvc_powertrain_prop.csv\n",
    "df_comsvc_powertrain = df_sql2.groupby(['category', 'fuel_type'])['dmv_registration_id'].count().reset_index(name ='count')\n",
    "df_car = df_comsvc_powertrain.loc[df_comsvc_powertrain['category'] == 'car']\n",
    "df_lt = df_comsvc_powertrain.loc[df_comsvc_powertrain['category'] == 'light truck']\n",
    "df_car = df_car.groupby('count').apply(my_fuel)         \n",
    "df_lt = df_lt.groupby('count').apply(my_fuel)   \n",
    "carList = df_car.sum(axis = 0, skipna = True).to_list()\n",
    "carperList = [round(i/sum(carList),4)  for i in carList]\n",
    "ltList = df_lt.sum(axis = 0, skipna = True).to_list()\n",
    "ltperList = [round(i/sum(ltList),4)  for i in ltList]\n",
    "list_comsvc_powertrain = carperList + ltperList\n",
    "df_compow = pd.read_csv(_join(target_path, 'inputs', 'region_comsvc_powertrain_prop.csv'))\n",
    "df_new = pd.DataFrame(columns = df_compow.columns.to_list())\n",
    "i = 0\n",
    "for row in ComSvcPow:\n",
    "    if i == 0:\n",
    "         row = [scenario_list[i][0]] + list_comsvc_powertrain\n",
    "    else:\n",
    "         row = [scenario_list[i][0]] + row\n",
    "    df_new.loc[i] = row \n",
    "    i += 1\n",
    "df_new['Year'] = df_new['Year'].astype('int64')\n",
    "df_new.to_csv(_join(target_path, 'inputs', 'region_comsvc_powertrain_prop.csv'), index = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_hvytrk_powertrain_prop.csv\n",
    "df_ht = df_comsvc_powertrain.loc[df_comsvc_powertrain['category'] == 'Heavy Truck']\n",
    "df_ht = df_ht.groupby('count').apply(my_fuel)   \n",
    "htList = df_ht.sum(axis = 0, skipna = True).to_list()\n",
    "htperList = [round(i/sum(htList),4)  for i in htList]\n",
    "df_hvypow = pd.read_csv(_join(target_path, 'inputs', 'region_hvytrk_powertrain_prop.csv'))\n",
    "df_new = pd.DataFrame(columns = df_hvypow.columns.to_list())\n",
    "i = 0\n",
    "for row in hvytrk_powertrain_prop:\n",
    "    if i == 0:\n",
    "         row = [scenario_list[i][0]] + htperList\n",
    "    else:\n",
    "         row = [scenario_list[i][0]] + row\n",
    "    df_new.loc[i] = row \n",
    "    i += 1\n",
    "df_new['Year'] = df_new['Year'].astype('int64')\n",
    "df_new.to_csv(_join(target_path, 'inputs', 'region_hvytrk_powertrain_prop.csv'), index = False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region_comsvc_lttrk_prop.csv\n",
    "df_vehtype = df_sql2.groupby(['category'])['dmv_registration_id'].count().reset_index(name ='count')\n",
    "df_vehtype['percent'] = (round(df_vehtype['count'] / df_vehtype['count'].sum(),2))\n",
    "df_comlt = pd.read_csv(_join(target_path, 'inputs', 'region_comsvc_lttrk_prop.csv'))\n",
    "df_new = pd.DataFrame(columns = df_comlt.columns.to_list())\n",
    "i = 0\n",
    "lt_base_persent = df_vehtype['percent'].loc[df_vehtype['category'] == 'light truck'].to_list()\n",
    "for row in ComSvcLtTrkProp:\n",
    "    if i == 0:\n",
    "         row = [scenario_list[i][0]] + lt_base_persent\n",
    "    else:\n",
    "         row = [scenario_list[i][0]] + [row]\n",
    "    df_new.loc[i] = row \n",
    "    i += 1\n",
    "df_new.to_csv(_join(target_path, 'inputs', 'region_comsvc_lttrk_prop.csv'), index = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
