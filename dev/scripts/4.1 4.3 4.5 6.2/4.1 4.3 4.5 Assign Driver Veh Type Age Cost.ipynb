{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "_join = os.path.join\n",
    "toolpath = os.getcwd()\n",
    "\n",
    "CONFIG = r'T:/ABM/ABM_FY22/RSM/VisionEval/Model/Update_Automations/settings.yml'\n",
    "with open(CONFIG) as cff:\n",
    "    config =yaml.safe_load(cff)\n",
    "target_path = ''.join(config['target_path'])\n",
    "scenpath = ''.join(config['scenpath'])\n",
    "scenario_list = config['scenario_list']\n",
    "AzoneCount = config['AzoneCount']\n",
    "lttrkPropGrwoth = config['lttrkPropGrwoth']\n",
    "autoAgeGrowth = config['autoAgeGrowth']\n",
    "truckAgeGrowth = config['truckAgeGrowth']\n",
    "VehOwnFlatRateFee = config['VehOwnFlatRateFee.2015']\n",
    "VehOwnAdValoremTax = config['VehOwnAdValoremTax']\n",
    "PaydHhProp = config['PaydHhProp']\n",
    "ave_driver_growth = config['ave_driver_growth']\n",
    "driverHTSBin = config['driverHTSBin']\n",
    "ageBin = config['ageBin']\n",
    "\n",
    "df_hh = pd.read_csv(_join(toolpath, 'SDRTS_Household_Data_20170731 TAZ(2016HTS).csv'))\n",
    "df_hh = df_hh[['hhid', 'hh_final_weight_456x', 'home_address_TAZ']]\n",
    "df_geo = pd.read_csv(_join(target_path, 'defs\\geo.csv'))\n",
    "df_geo = df_geo[['Azone', 'Bzone']]\n",
    "df_geo.rename(columns={'Bzone':'home_address_TAZ'}, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Assign Drivers - VE drive age bin. Reclassify HTS driver age bin to VE driver age bin using ABM persons age\n",
    "# bin as a split and joint reference. See drivers age bin calculation.xlsx in the same locatioin for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person = pd.read_csv(_join(toolpath, 'SDRTS_Person_Data_20170731(2016HTS).csv'))\n",
    "df_person = df_person[['hhid','age','license','hh_final_weight_456x']]\n",
    "labels = ['DrvPerPrsn0to15', 'DrvPerPrsn16to24','DrvPerPrsn25to34','DrvPerPrsn35to54','DrvPerPrsn55to64','DrvPerPrsn65Plus']\n",
    "df_person['driveBins'] = pd.cut(df_person['age'], bins=driverHTSBin, labels=labels, include_lowest=True)\n",
    "df_person['license'] = df_person['license'].fillna(2)\n",
    "df_perGro = df_person.groupby(['driveBins', 'license'])['hh_final_weight_456x'].sum().reset_index(name ='Sum')\n",
    "scenario = scenario_list[0][1]\n",
    "age_bin2 = [0, 14,15,19,24,29,34,54,64,150] \n",
    "age_labels = ['0-14','15','16-19','20-24','25-29','30-34','35-54','55-64','65+']\n",
    "df_personABM = pd.read_csv(_join(scenpath, scenario, 'input\\persons.csv'))[['perid','age']]\n",
    "df_personABM['personBins'] = pd.cut(df_personABM['age'], bins=age_bin2, labels=age_labels , include_lowest=True)\n",
    "df_personABM = df_personABM.groupby(['personBins'])['perid'].count().reset_index(name ='Sum')\n",
    "personABM_list = df_personABM['Sum'].to_list()\n",
    "personABMper_list = []\n",
    "personABMper_list.append(personABM_list[0]/(personABM_list[0]+personABM_list[1]))\n",
    "personABMper_list.append(personABM_list[1]/(personABM_list[0]+personABM_list[1]))\n",
    "personABMper_list.append(personABM_list[2]/(personABM_list[2]+personABM_list[3]))\n",
    "personABMper_list.append(personABM_list[3]/(personABM_list[2]+personABM_list[3]))\n",
    "personABMper_list.append(personABM_list[4]/(personABM_list[4]+personABM_list[5]))\n",
    "personABMper_list.append(personABM_list[5]/(personABM_list[4]+personABM_list[5]))\n",
    "df_perGro2 = df_perGro.pivot_table(columns='license', values='Sum', index=['driveBins'], aggfunc=np.sum).rename_axis(None, axis=1)\n",
    "df_perGro2[1.0] = df_perGro2[1.0].fillna(0)\n",
    "driver_list = df_perGro2[1.0].to_list()\n",
    "nodriver_list = df_perGro2[2.0].to_list()\n",
    "list_all = [] # this list includes both driver and nodriver)\n",
    "for list in [driver_list, nodriver_list]:\n",
    "    list_all.append(list[0]*personABMper_list[0])\n",
    "    list_all.append(list[0]*personABMper_list[1]+list[1]*personABMper_list[2])\n",
    "    list_all.append(list[1]*personABMper_list[3]+list[2]*personABMper_list[4])\n",
    "    list_all.append(list[2]*personABMper_list[5]+list[3])\n",
    "    list_all.append(list[4])\n",
    "    list_all.append(list[5])\n",
    "driver2_list,nodriver2_list = list_all[:int(len(list_all)/2)],list_all[int(len(list_all)/2):]\n",
    "nodriver2_list[1:]\n",
    "new_label = ['DrvPerPrsn15to19','DrvPerPrsn20to29','DrvPerPrsn30to54','DrvPerPrsn55to64','DrvPerPrsn65Plus']\n",
    "drive_dic={'driveBins': new_label, 'lic': driver2_list[1:], 'nolic':nodriver2_list[1:]}\n",
    "df_perGro2 =pd.DataFrame(drive_dic)\n",
    "df_perGro2['value'] = df_perGro2['lic'] / (df_perGro2['lic'] + df_perGro2['nolic'])\n",
    "#df_perGro2 = df_perGro2.drop(['lic','nolic'], axis=1)\n",
    "df_perPiv3 = df_perGro2.pivot_table(columns='driveBins', values='value').rename_axis(None, axis=1)\n",
    "df_perPiv3.reset_index(drop=True, inplace=True)\n",
    "df_perPiv3['Year'] = scenario_list[0][0]\n",
    "first_column = df_perPiv3.pop('Year')\n",
    "df_perPiv3.insert(0, 'Year', first_column)\n",
    "baseList = df_perPiv3.values.tolist()[0]\n",
    "futureList = [a * b for a, b in zip(baseList, ave_driver_growth)]\n",
    "futureList[0] = scenario_list[1][0]\n",
    "df_perPiv3.loc[len(df_perPiv3.index)] = futureList\n",
    "df_perPiv3['Year'] = df_perPiv3['Year'].astype('int64')\n",
    "df_perPiv3.to_csv(_join(target_path, 'inputs\\\\region_hh_ave_driver_per_capita.csv'), index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Assign Vehicle Type and 4.5 Assign Vehicle Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_htsveh = pd.read_csv(_join(toolpath, 'SDRTS_Vehicle_Data_20170731(2016HTS).csv'))\n",
    "df_htsveh['make'] = df_htsveh['make'].str.lower()\n",
    "df_htsveh['model'] = df_htsveh['model'].str.lower()\n",
    "df_htsveh['category'] = \"\"\n",
    "#df_htsveh = df_htsveh[['hhid', 'year', 'make', 'model', 'fuel']]\n",
    "df_vehset = pd.read_csv(_join(toolpath, 'vehicle class dataset-lookup.csv'))\n",
    "df_vehset['Make'] = df_vehset['Make'].str.lower()\n",
    "df_vehset['Model'] = df_vehset['Model'].str.lower()\n",
    "df_except = pd.read_csv(_join(toolpath, 'exception.csv'))\n",
    "df_except['Model'] = df_except['Model'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ind in df_htsveh.index:\n",
    "    if ind < 100000000000000000:\n",
    "        df_select = df_vehset[df_vehset['Make'].str.contains(df_htsveh['make'][ind])]\n",
    "        df_excesel = df_except[df_except['Make'].str.contains(df_htsveh['make'][ind])]\n",
    "        if not df_select.empty:\n",
    "            #print ('bbb', df_select)\n",
    "            try:\n",
    "                item = df_select[df_select['Model'].str.contains(df_htsveh['model'][ind])]['Category3'].to_list()[0]\n",
    "                df_htsveh['category'][ind] = item\n",
    "            except:\n",
    "                #print ('a1', df_htsveh['model'][ind])\n",
    "                for j in df_select.index:\n",
    "                    if df_select['Model'][j] in df_htsveh['model'][ind]:\n",
    "                        #print ('a2', ind, df_select['Model'][j], df_htsveh['model'][ind], df_select['Category3'][j])\n",
    "                        df_htsveh['category'][ind] = df_select['Category3'][j]\n",
    "                        continue            \n",
    "                if  df_htsveh['category'][ind] == \"\" and not df_excesel.empty:\n",
    "                    try:\n",
    "                        item2 = df_excesel[df_excesel['Model'].str.contains(df_htsveh['model'][ind])]['Category3'].to_list()[0]\n",
    "                        df_htsveh['category'][ind] = item2\n",
    "                    except:\n",
    "                        continue\n",
    "        else:\n",
    "            if  df_htsveh['category'][ind] == \"\" and not df_excesel.empty:\n",
    "                try:\n",
    "                    item2 = df_excesel[df_excesel['Model'].str.contains(df_htsveh['model'][ind])]['Category3'].to_list()[0]\n",
    "                    df_htsveh['category'][ind] = item2\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "df_htsvehf = df_htsveh.merge(df_hh, on = ['hhid'], how = 'inner')\n",
    "df_htsvehf = df_htsvehf.merge(df_geo, on = ['home_address_TAZ'], how = 'inner')\n",
    "df_htsvehf = df_htsvehf[df_htsvehf.category != \"\"]\n",
    "df_group =  df_htsvehf.groupby(['category', 'Azone'])['hh_final_weight_456x'].sum().reset_index(name ='Sum')\n",
    "df=df_group.pivot_table(index='Azone', columns='category', values='Sum').reset_index().rename_axis(None, axis=1)\n",
    "df[scenario_list[0][0]] = df['light truck'] / (df['car'] + df['light truck'])\n",
    "df = df[['Azone', scenario_list[0][0]]]\n",
    "df[scenario_list[1][0]] = df[scenario_list[0][0]]/lttrkPropGrwoth\n",
    "df = pd.melt(df, id_vars=['Azone'])\n",
    "df.rename(columns={'Azone':'Geo','variable':'Year','value':'LtTrkProp'}, inplace=True) \n",
    "df = df.round({'LtTrkProp': 2})\n",
    "df.to_csv(_join(target_path, 'inputs\\\\azone_hh_lttrk_prop.csv'), index = False) \n",
    "df.to_csv(_join(target_path, 'inputs\\\\azone_lttrk_prop.csv'), index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.5 Assign Vehicle Age\n",
    "todays_date = date.today()\n",
    "df_htsvehf['age'] = todays_date.year - df_htsvehf['year']\n",
    "df_age1 =  df_htsvehf.groupby(['category', 'Azone'])['age'].mean().reset_index(name ='mean')\n",
    "df_age2 = df_age1.pivot_table(index='Azone', columns='category', values='mean').reset_index().rename_axis(None, axis=1)\n",
    "df_age2.rename(columns={'Azone':'Geo','car':'AutoMeanAge', 'light truck':'LtTrkMeanAge'}, inplace=True) \n",
    "df_age2.insert(loc=1, column='Year', value=scenario_list[0][0])\n",
    "df_age3 = df_age2.copy()\n",
    "df_age3['AutoMeanAge'] = df_age2['AutoMeanAge'] * autoAgeGrowth\n",
    "df_age3['LtTrkMeanAge'] = df_age2['LtTrkMeanAge'] * truckAgeGrowth\n",
    "df_age3['Year'] =scenario_list[1][0]\n",
    "df_age2 = df_age2.append(df_age3)\n",
    "df_age2['Year'] = df_age2['Year'].astype('int64')\n",
    "df_age2 = df_age2.round({'AutoMeanAge': 2, 'LtTrkMeanAge': 2})\n",
    "df_age2['AutoMeanAge'][df_age2['AutoMeanAge'] >= 14] = 14\n",
    "df_age2['LtTrkMeanAge'][df_age2['LtTrkMeanAge'] >= 14] = 14\n",
    "df_age2.to_csv(_join(target_path, 'inputs\\\\azone_hh_veh_mean_age.csv'), index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Assign Drivers - older"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person = pd.read_csv(_join(toolpath, 'SDRTS_Person_Data_20170731(2016HTS).csv'))\n",
    "df_person = df_person[['hhid','age','license','hh_final_weight_456x']]\n",
    "labels = ['Under', 'DrvPerPrsn16to24','DrvPerPrsn25to34','DrvPerPrsn35to54','DrvPerPrsn55to64','DrvPerPrsn65Plus']\n",
    "df_person['driveBins'] = pd.cut(df_person['age'], bins=ageBin, labels=labels, include_lowest=True)\n",
    "df_perGro = df_person.groupby(['driveBins', 'license'])['hh_final_weight_456x'].sum().reset_index(name ='Sum')\n",
    "df_perPiv = df_perGro.pivot_table(index='driveBins', columns='license', values='Sum').reset_index().rename_axis(None, axis=1)\n",
    "df_perPiv['value'] = df_perPiv[1.0] / (df_perPiv[1.0] + df_perPiv[2.0])\n",
    "df_perPiv = df_perPiv.drop([1.0, 2.0], axis=1)\n",
    "df_perPiv2 = df_perPiv.pivot_table(columns='driveBins', values='value').rename_axis(None, axis=1)\n",
    "df_perPiv2.reset_index(drop=True, inplace=True)\n",
    "df_perPiv2.columns = df_perPiv2.columns.add_categories(['Year'])\n",
    "df_perPiv2.insert(loc=0, column='Year', value=scenario_list[0][0])\n",
    "baseList = df_perPiv2.values.tolist()[0]\n",
    "futureList = [a * b for a, b in zip(baseList, ave_driver_growth)]\n",
    "futureList[0] = scenario_list[1][0]\n",
    "df_perPiv2.loc[len(df_perPiv2.index)] = futureList\n",
    "df_perPiv2['Year'] = df_perPiv2['Year'].astype('int64')\n",
    "# df_perPiv2.to_csv(_join(target_path, 'inputs\\\\region_hh_ave_driver_per_capita.csv'), index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_htsveh.to_csv(_join(toolpath, 'Vehicle_Data.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
