{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Thu Sep 29 11:19:21 2021\n",
    "@author: cliu\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "import yaml\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "_join = os.path.join\n",
    "toolpath = os.getcwd()\n",
    "\n",
    "CONFIG = r'T:\\ABM\\ABM_FY22\\RSM\\VisionEval\\Model\\Update_Automations/settings.yml'\n",
    "with open(CONFIG) as cff:\n",
    "    config =yaml.safe_load(cff)\n",
    "scenario_list = config['scenario_list']\n",
    "target_path = ''.join(config['target_path'])\n",
    "ComSvcPow = config['ComSvcPow']\n",
    "hvytrk_powertrain_prop = config['hvytrk_powertrain_prop']\n",
    "ComSvcLtTrkProp = config['ComSvcLtTrkProp']\n",
    "AveComSvcVehicleAge = config['AveComSvcVehicleAge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(\"DRIVER={SQL Server};\"\n",
    "                      \"SERVER=DDAMWSQL16;\"\n",
    "                      \"DATABASE=dpoe_stage;\" \n",
    "                      \"Trusted_Connection=yes;\")\n",
    "sql2 = (\"SELECT * FROM [dpoe_stage].[veh_reg_dmv].[fact] where yr=2017 and own = 'Commercial' and not make is null and not series is null\")\n",
    "df_sql2 = pd.read_sql_query(sql2, conn)\n",
    "df_sql2['make'] = df_sql2['make'].str.lower()\n",
    "df_sql2['series'] = df_sql2['series'].str.lower()\n",
    "df_sql2['category'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comm = pd.read_csv(_join(toolpath, 'dmv commercial vehicle class dataset-lookup.csv'))\n",
    "df_comm['make'] = df_comm['make'].str.lower()\n",
    "df_comm['series'] = df_comm['series'].str.lower()\n",
    "df_vehset = pd.read_csv(_join(toolpath, 'vehicle class dataset-lookup.csv'))\n",
    "df_vehset['Make'] = df_vehset['Make'].str.lower()\n",
    "df_vehset['Model'] = df_vehset['Model'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 20000\n",
    "df_dmvexcept = pd.DataFrame(columns=df_sql2.columns)\n",
    "for ind in df_sql2.index:  # classify 'category' to each record (vehicle) and sum up each category\n",
    "    if ind < 100000000000000000000001:\n",
    "        df_select = df_vehset[df_vehset['Make'].str.contains(df_sql2['make'][ind])]\n",
    "        df_commsel = df_comm[df_comm['make'].str.contains(df_sql2['make'][ind])]        \n",
    "        if not df_select.empty: # for the same make in df_vehset and df_sql2\n",
    "            #process.extractOne(df_sql2['series'][ind], df_select['Model'])           \n",
    "            try:\n",
    "                item = process.extractOne(df_sql2['series'][ind], df_select['Model']) # there is the same model\n",
    "                df_sql2['category'][ind] = df_select.loc[[item[2]]]['Category3'].to_list()[0]\n",
    "                #print ('a111', df_select.loc[[item[2]]]['Category3'].to_list()[0])\n",
    "            except:\n",
    "                print ('a222', df_sql2['model'][ind])\n",
    "        elif not df_commsel.empty: # for the same make in df_comm and df_sql2\n",
    "                #process.extractOne(df_sql2['series'][ind], df_commsel['series'])           \n",
    "            try:\n",
    "                item = process.extractOne(df_sql2['series'][ind],  df_commsel['series'])  # there is the same model\n",
    "                df_sql2['category'][ind] = df_commsel.loc[[item[2]]]['category'].to_list()[0]\n",
    "                #print ('a333',  df_commsel.loc[[item[2]]]['category'].to_list()[0])\n",
    "            except:\n",
    "                print ('a444', df_sql2['model'][ind]) \n",
    "        else: # there is no same make in df_htsveh\n",
    "            df_dmvexcept = df_dmvexcept.append(df_sql2.loc[[ind]])\n",
    "            print ('a555')\n",
    "        if ind % counter == 0:\n",
    "            print (\"processed\", ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fuel(x):\n",
    "    names = {\n",
    "        'Ice': x[(x['fuel_type']=='COMPRESSED NGASOLINE')|(x['fuel_type']=='DIESEL')|(x['fuel_type']=='FLEX METHANOL')|(x['fuel_type']=='GASOLINE')|(x['fuel_type']=='NATURAL GAS')|(x['fuel_type']=='PROPANE')|(x['fuel_type']=='HYDROGENATURAL GAS')]['count'].sum(),\n",
    "        'Hev': x[(x['fuel_type']=='FXELECTRIC')|(x['fuel_type']=='HGASOLINE')|(x['fuel_type']=='PHEV')]['count'].sum(),\n",
    "        'Bev': x[x['fuel_type']=='ELECTRIC']['count'].sum()}\n",
    "    return pd.Series(names)\n",
    "\n",
    "# region_comsvc_powertrain_prop.csv\n",
    "df_comsvc_powertrain = df_sql2.groupby(['category', 'fuel_type'])['dmv_registration_id'].count().reset_index(name ='count')\n",
    "df_car = df_comsvc_powertrain.loc[df_comsvc_powertrain['category'] == 'car']\n",
    "df_lt = df_comsvc_powertrain.loc[df_comsvc_powertrain['category'] == 'light truck']\n",
    "df_car = df_car.groupby('count').apply(my_fuel)         \n",
    "df_lt = df_lt.groupby('count').apply(my_fuel)   \n",
    "carList = df_car.sum(axis = 0, skipna = True).to_list()\n",
    "carperList = [round(i/sum(carList),4)  for i in carList]\n",
    "ltList = df_lt.sum(axis = 0, skipna = True).to_list()\n",
    "ltperList = [round(i/sum(ltList),4)  for i in ltList]\n",
    "list_comsvc_powertrain = carperList + ltperList\n",
    "df_compow = pd.read_csv(_join(target_path, 'inputs', 'region_comsvc_powertrain_prop.csv'))\n",
    "df_new = pd.DataFrame(columns = df_compow.columns.to_list())\n",
    "i = 0\n",
    "for row in ComSvcPow:\n",
    "    if i == 0:\n",
    "         row = [scenario_list[i][0]] + list_comsvc_powertrain\n",
    "    else:\n",
    "         row = [scenario_list[i][0]] + row\n",
    "    df_new.loc[i] = row \n",
    "    i += 1\n",
    "df_new['Year'] = df_new['Year'].astype('int64')\n",
    "df_new.to_csv(_join(target_path, 'inputs', 'region_comsvc_powertrain_prop.csv'), index = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_hvytrk_powertrain_prop.csv\n",
    "df_ht = df_comsvc_powertrain.loc[df_comsvc_powertrain['category'] == 'Heavy Truck']\n",
    "df_ht = df_ht.groupby('count').apply(my_fuel)   \n",
    "htList = df_ht.sum(axis = 0, skipna = True).to_list()\n",
    "htperList = [round(i/sum(htList),4)  for i in htList]\n",
    "df_hvypow = pd.read_csv(_join(target_path, 'inputs', 'region_hvytrk_powertrain_prop.csv'))\n",
    "df_new = pd.DataFrame(columns = df_hvypow.columns.to_list())\n",
    "i = 0\n",
    "for row in hvytrk_powertrain_prop:\n",
    "    if i == 0:\n",
    "         row = [scenario_list[i][0]] + htperList\n",
    "    else:\n",
    "         row = [scenario_list[i][0]] + row\n",
    "    df_new.loc[i] = row \n",
    "    i += 1\n",
    "df_new['Year'] = df_new['Year'].astype('int64')\n",
    "df_new.to_csv(_join(target_path, 'inputs', 'region_hvytrk_powertrain_prop.csv'), index = False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region_comsvc_lttrk_prop.csv\n",
    "df_vehtype = df_sql2.groupby(['category'])['dmv_registration_id'].count().reset_index(name ='count')\n",
    "df_vehtype['percent'] = (round(df_vehtype['count'] / df_vehtype['count'].sum(),2))\n",
    "df_comlt = pd.read_csv(_join(target_path, 'inputs', 'region_comsvc_lttrk_prop.csv'))\n",
    "df_new = pd.DataFrame(columns = df_comlt.columns.to_list())\n",
    "i = 0\n",
    "lt_base_percent = df_vehtype['percent'].loc[df_vehtype['category'] == 'light truck'].to_list()\n",
    "for row in ComSvcLtTrkProp:\n",
    "    if i == 0:\n",
    "         row = [scenario_list[i][0]] + lt_base_percent\n",
    "    else:\n",
    "         row = [scenario_list[i][0]] + [row]\n",
    "    df_new.loc[i] = row \n",
    "    i += 1\n",
    "df_new.to_csv(_join(target_path, 'inputs', 'region_comsvc_lttrk_prop.csv'), index = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize-vepowertrainsandfuels - region_comsvc_ave_veh_age.csv\n",
    "df_comage = pd.read_csv(_join(target_path, 'inputs', 'region_comsvc_ave_veh_age.csv'))\n",
    "df_comage['AveComSvcVehicleAge'] = AveComSvcVehicleAge\n",
    "df_comage.to_csv(_join(target_path, 'inputs', 'region_comsvc_ave_veh_age.csv'), index = False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder Azone input files\n",
    "df_azoneseq = pd.read_csv(_join(CONFIG[:-13], 'Azone_Sequence.csv'))\n",
    "onlyfiles = [f for f in listdir(r'T:\\ABM\\ABM_FY22\\RSM\\VisionEval\\Model\\VE-R4.0.2_2020-10-21\\models\\SDRSPM\\inputs\\CL') \\\n",
    "             if isfile(_join(r'T:\\ABM\\ABM_FY22\\RSM\\VisionEval\\Model\\VE-R4.0.2_2020-10-21\\models\\SDRSPM\\inputs\\CL', f))]\n",
    "for file in onlyfiles:\n",
    "    print (file)\n",
    "    if 'azone' in file:\n",
    "        df_temp = pd.read_csv(_join('T:\\ABM\\ABM_FY22\\RSM\\VisionEval\\Model\\VE-R4.0.2_2020-10-21\\models\\SDRSPM\\inputs\\CL', file))\n",
    "        df_temp = df_temp.merge(df_azoneseq, on='Geo', how='left')\n",
    "        df_temp = df_temp.sort_values(['Year', 'Order'], ascending=[1, 1])\n",
    "        df_temp = df_temp.drop(columns=['Order'])\n",
    "        df_temp.to_csv(_join('T:\\ABM\\ABM_FY22\\RSM\\VisionEval\\Model\\VE-R4.0.2_2020-10-21\\models\\SDRSPM\\inputs\\CL',file), index=False)\n",
    "        print (df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
