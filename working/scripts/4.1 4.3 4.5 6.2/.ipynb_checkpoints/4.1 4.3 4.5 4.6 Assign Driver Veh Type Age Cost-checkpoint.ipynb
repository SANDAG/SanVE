{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "_join = os.path.join\n",
    "toolpath = os.getcwd()\n",
    "\n",
    "CONFIG = r'T:/ABM/ABM_FY21/Sketch_Planning/VisionEval/Model/Update_Automations/settings.yml'\n",
    "with open(CONFIG) as cff:\n",
    "    config =yaml.safe_load(cff)\n",
    "target_path = ''.join(config['target_path'])\n",
    "scenpath = ''.join(config['scenpath'])\n",
    "scenario_list = config['scenario_list']\n",
    "AzoneCount = config['AzoneCount']\n",
    "lttrkPropGrwoth = config['lttrkPropGrwoth']\n",
    "autoAgeGrowth = config['autoAgeGrowth']\n",
    "truckAgeGrowth = config['truckAgeGrowth']\n",
    "VehOwnFlatRateFee = config['VehOwnFlatRateFee.2015']\n",
    "VehOwnAdValoremTax = config['VehOwnAdValoremTax']\n",
    "PaydHhProp = config['PaydHhProp']\n",
    "ave_driver_growth = config['ave_driver_growth']\n",
    "ageBin = config['ageBin']\n",
    "\n",
    "df_hh = pd.read_csv(_join(toolpath, 'SDRTS_Household_Data_20170731 TAZ(2016HTS).csv'))\n",
    "df_hh = df_hh[['hhid', 'hh_final_weight_456x', 'home_address_TAZ']]\n",
    "df_geo = pd.read_csv(_join(target_path, 'defs\\geo.csv'))\n",
    "df_geo = df_geo[['Azone', 'Bzone']]\n",
    "df_geo.rename(columns={'Bzone':'home_address_TAZ'}, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Assign Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person = pd.read_csv(_join(toolpath, 'SDRTS_Person_Data_20170731(2016HTS).csv'))\n",
    "df_person = df_person[['hhid','age','license','hh_final_weight_456x']]\n",
    "labels = ['Under', 'DrvPerPrsn16to24','DrvPerPrsn25to34','DrvPerPrsn35to54','DrvPerPrsn55to64','DrvPerPrsn65Plus']\n",
    "df_person['driveBins'] = pd.cut(df_person['age'], bins=ageBin, labels=labels, include_lowest=True)\n",
    "df_perGro = df_person.groupby(['driveBins', 'license'])['hh_final_weight_456x'].sum().reset_index(name ='Sum')\n",
    "df_perPiv = df_perGro.pivot_table(index='driveBins', columns='license', values='Sum').reset_index().rename_axis(None, axis=1)\n",
    "df_perPiv['value'] = df_perPiv[1.0] / (df_perPiv[1.0] + df_perPiv[2.0])\n",
    "df_perPiv = df_perPiv.drop([1.0, 2.0], axis=1)\n",
    "df_perPiv2 = df_perPiv.pivot_table(columns='driveBins', values='value').rename_axis(None, axis=1)\n",
    "df_perPiv2.reset_index(drop=True, inplace=True)\n",
    "df_perPiv2.columns = df_perPiv2.columns.add_categories(['Year'])\n",
    "df_perPiv2.insert(loc=0, column='Year', value=scenario_list[0][0])\n",
    "baseList = df_perPiv2.values.tolist()[0]\n",
    "futureList = [a * b for a, b in zip(baseList, ave_driver_growth)]\n",
    "futureList[0] = scenario_list[1][0]\n",
    "df_perPiv2.loc[len(df_perPiv2.index)] = futureList\n",
    "df_perPiv2['Year'] = df_perPiv2['Year'].astype('int64')\n",
    "df_perPiv2.to_csv(_join(target_path, 'inputs\\\\region_hh_ave_driver_per_capita.csv'), index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Assign Vehicle Type and 4.5 Assign Vehicle Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_htsveh = pd.read_csv(_join(toolpath, 'SDRTS_Vehicle_Data_20170731(2016HTS).csv'))\n",
    "df_htsveh['make'] = df_htsveh['make'].str.lower()\n",
    "df_htsveh['model'] = df_htsveh['model'].str.lower()\n",
    "df_htsveh['category'] = \"\"\n",
    "#df_htsveh = df_htsveh[['hhid', 'year', 'make', 'model', 'fuel']]\n",
    "df_vehset = pd.read_csv(_join(toolpath, 'vehicle class dataset-lookup.csv'))\n",
    "df_vehset['Make'] = df_vehset['Make'].str.lower()\n",
    "df_vehset['Model'] = df_vehset['Model'].str.lower()\n",
    "df_except = pd.read_csv(_join(toolpath, 'exception.csv'))\n",
    "df_except['Model'] = df_except['Model'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jyen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\jyen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "for ind in df_htsveh.index:\n",
    "    if ind < 100000000000000000:\n",
    "        df_select = df_vehset[df_vehset['Make'].str.contains(df_htsveh['make'][ind])]\n",
    "        df_excesel = df_except[df_except['Make'].str.contains(df_htsveh['make'][ind])]\n",
    "        if not df_select.empty:\n",
    "            #print ('bbb', df_select)\n",
    "            try:\n",
    "                item = df_select[df_select['Model'].str.contains(df_htsveh['model'][ind])]['Category3'].to_list()[0]\n",
    "                df_htsveh['category'][ind] = item\n",
    "            except:\n",
    "                #print ('a1', df_htsveh['model'][ind])\n",
    "                for j in df_select.index:\n",
    "                    if df_select['Model'][j] in df_htsveh['model'][ind]:\n",
    "                        #print ('a2', ind, df_select['Model'][j], df_htsveh['model'][ind], df_select['Category3'][j])\n",
    "                        df_htsveh['category'][ind] = df_select['Category3'][j]\n",
    "                        continue            \n",
    "                if  df_htsveh['category'][ind] == \"\" and not df_excesel.empty:\n",
    "                    try:\n",
    "                        item2 = df_excesel[df_excesel['Model'].str.contains(df_htsveh['model'][ind])]['Category3'].to_list()[0]\n",
    "                        df_htsveh['category'][ind] = item2\n",
    "                    except:\n",
    "                        continue\n",
    "        else:\n",
    "            if  df_htsveh['category'][ind] == \"\" and not df_excesel.empty:\n",
    "                try:\n",
    "                    item2 = df_excesel[df_excesel['Model'].str.contains(df_htsveh['model'][ind])]['Category3'].to_list()[0]\n",
    "                    df_htsveh['category'][ind] = item2\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "df_htsvehf = df_htsveh.merge(df_hh, on = ['hhid'], how = 'inner')\n",
    "df_htsvehf = df_htsvehf.merge(df_geo, on = ['home_address_TAZ'], how = 'inner')\n",
    "df_htsvehf = df_htsvehf[df_htsvehf.category != \"\"]\n",
    "df_group =  df_htsvehf.groupby(['category', 'Azone'])['hh_final_weight_456x'].sum().reset_index(name ='Sum')\n",
    "df=df_group.pivot_table(index='Azone', columns='category', values='Sum').reset_index().rename_axis(None, axis=1)\n",
    "df[scenario_list[0][0]] = df['light truck'] / (df['car'] + df['light truck'])\n",
    "df = df[['Azone', scenario_list[0][0]]]\n",
    "df[scenario_list[1][0]] = df[scenario_list[0][0]]/lttrkPropGrwoth\n",
    "df = pd.melt(df, id_vars=['Azone'])\n",
    "df.rename(columns={'Azone':'Geo','variable':'Year','value':'LtTrkProp'}, inplace=True) \n",
    "df = df.round({'LtTrkProp': 2})\n",
    "df.to_csv(_join(target_path, 'inputs\\\\azone_hh_lttrk_prop.csv'), index = False) \n",
    "df.to_csv(_join(target_path, 'inputs\\\\azone_lttrk_prop.csv'), index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.5 Assign Vehicle Age\n",
    "todays_date = date.today()\n",
    "df_htsvehf['age'] = todays_date.year - df_htsvehf['year']\n",
    "df_age1 =  df_htsvehf.groupby(['category', 'Azone'])['age'].mean().reset_index(name ='mean')\n",
    "df_age2 = df_age1.pivot_table(index='Azone', columns='category', values='mean').reset_index().rename_axis(None, axis=1)\n",
    "df_age2.rename(columns={'car':'AutoMeanAge', 'light truck':'LtTrkMeanAge'}, inplace=True) \n",
    "df_age2.insert(loc=1, column='Year', value=scenario_list[0][0])\n",
    "df_age3 = df_age2.copy()\n",
    "df_age3['AutoMeanAge'] = df_age2['AutoMeanAge'] * autoAgeGrowth\n",
    "df_age3['LtTrkMeanAge'] = df_age2['LtTrkMeanAge'] * truckAgeGrowth\n",
    "df_age3['Year'] =scenario_list[1][0]\n",
    "df_age2 = df_age2.append(df_age3)\n",
    "df_age2['Year'] = df_age2['Year'].astype('int64')\n",
    "df_age2 = df_age2.round({'AutoMeanAge': 2, 'LtTrkMeanAge': 2})\n",
    "df_age2.to_csv(_join(target_path, 'inputs\\\\azone_hh_veh_mean_age.csv'), index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_htsveh.to_csv(_join(toolpath, 'Vehicle_Data.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
