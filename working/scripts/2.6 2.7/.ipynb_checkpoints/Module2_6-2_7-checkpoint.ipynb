{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "_join = os.path.join\n",
    "\n",
    "CONFIG = r'T:/ABM/ABM_FY21/Sketch_Planning/VisionEval/Model/Update_Automations/settings.yml'\n",
    "with open(CONFIG) as cff:\n",
    "    config =yaml.safe_load(cff)\n",
    "target_path = ''.join(config['target_path'])\n",
    "scenpath = ''.join(config['scenpath'])\n",
    "scenario_list = config['scenario_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6 Update bzone_parking.csv (simple average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 is done\n",
      "2035 is done\n"
     ]
    }
   ],
   "source": [
    "# PkgSpacesPerSFDU: 2, 2.5, 3, simple average if a taz contain multiple mgras with various Pseudo MSA \n",
    "# PkgSpacesPerMFDU: 1, 1.5, 3, simple average if a taz contain multiple mgras with various Pseudo MSA \n",
    "# PkgSpacesPerGQ: 0\n",
    "# PropNonWrkTripPay - Proportion of non-work trips who pay for parking\n",
    "# PropWkrPay - Proportion of workers working at jobs in the Bzone who pay for parking. Teleworkers are excluded from both numerator and demoniator\n",
    "# PropCashOut: 0\n",
    "# PkgCost.2010: simple average of mgra_mparkcost\n",
    "\n",
    "def my_agg(x):\n",
    "    names = {\n",
    "        'no praking': x[x['fp_choice']==-1]['Geo'].count(),\n",
    "        'free parking': x[x['fp_choice']==1]['Geo'].count(),\n",
    "        'paid': x[x['fp_choice']==2]['Geo'].count(),\n",
    "        'reimburse': x[x['fp_choice']==3]['Geo'].count()}\n",
    "    return pd.Series(names)\n",
    "def trip_agg(x):\n",
    "    names = {\n",
    "        'no pay': x[(x['dest_purpose']=='Escort')|(x['dest_purpose']=='Home')|(x['dest_purpose']=='Work')]['Geo'].count(),\n",
    "        'all': x['Geo'].count()}\n",
    "    return pd.Series(names)\n",
    "\n",
    "for year, scenario in scenario_list:\n",
    "    #PkgSpacesPerSFDU, PkgSpacesPerMFDU, PkgSpacesPerGQ, PkgCost.2010\n",
    "    df_parking = pd.DataFrame(list(range(13,4997,1)),columns=['Geo'])\n",
    "    df_mgra = pd.read_csv(_join(scenpath, scenario, 'input\\mgra13_based_input' + str(year) + '.csv'))\n",
    "    df_mgra.rename(columns={'taz':'Geo'}, inplace=True)  \n",
    "    \n",
    "    df_group = df_mgra.groupby('Geo', as_index=False).mean()\n",
    "    #df_group['PkgCost.2010'] = df_group['mstall_park']/df_group['mstall'] #weighted average parking\n",
    "    df_group['mparkcost'] = df_group['mparkcost'].fillna(0)\n",
    "    df_group['pseudomsa'] = round(df_group['pseudomsa']+0.0000001)   \n",
    "\n",
    "    df_parking = df_parking.merge(df_group, on=['Geo'], how = 'outer')  #get TAZ pseudomsa values from mgra.file, simple average\n",
    "    #df_parking = df_parking.merge(df_group, on=['Geo'], how = 'inner') #get TAZ pseudomsa values from mgra.file, simple average\n",
    "    #df_parking = df_parking.drop_duplicates(subset =['Geo']) \n",
    "    \n",
    "    #df_parking = df_parking.merge(df_group[['Geo', 'mparkcost']], on=['Geo'], how = 'outer')\n",
    "    df_parking.rename(columns={'mparkcost':'PkgCost.2010'}, inplace=True)    \n",
    "    \n",
    "    df_parking['PkgSpacesPerSFDU'] = np.where(df_parking['pseudomsa']==1, 2, np.where(df_parking['pseudomsa']>=4,3,2.5))\n",
    "    df_parking['PkgSpacesPerMFDU'] = np.where(df_parking['pseudomsa']==1, 1, np.where(df_parking['pseudomsa']>=4,3,1.5))\n",
    "    df_parking['PkgSpacesPerGQ'] = 0\n",
    "    df_parking = df_parking[['Geo','PkgSpacesPerSFDU','PkgSpacesPerMFDU','PkgSpacesPerGQ', 'PkgCost.2010']]\n",
    "    df_parking['PropCashOut'] = 0\n",
    "    #df_mgra['mstall'] =  df_mgra[[\"mstallsoth\", \"mstallssam\"]].max(axis=1) #weighted average parking\n",
    "    #df_mgra['mstall_park'] = df_mgra['mstall'] * df_mgra['mparkcost'] #weighted average parking\n",
    "\n",
    "    # PropWkrPay\n",
    "    df_woc = pd.read_csv(_join(scenpath, scenario, 'output\\wsLocResults_3.csv'))\n",
    "    df_woc = df_woc[['PersonID', 'WorkLocation']]\n",
    "    df_woc.rename(columns={'PersonID':'person_id', 'WorkLocation':'mgra'}, inplace=True)\n",
    "    df_person = pd.read_csv(_join(scenpath, scenario, 'output\\personData_3.csv'))\n",
    "    df_person = df_person[['person_id','type','fp_choice']]\n",
    "    df_person = df_person.merge(df_woc, on=['person_id'], how = 'outer')\n",
    "    df_person =df_person.merge(df_mgra[['mgra','Geo']], on=['mgra'], how = 'outer')\n",
    "    df_workPark = df_person.loc[(df_person['type']=='Full-time worker') | (df_person['type']=='Part-time worker') ]\n",
    "    df_workPark = df_workPark.groupby('Geo').apply(my_agg)    \n",
    "    df_workPark['PropWkrPay'] = (df_workPark['paid'] + df_workPark['reimburse'])/df_workPark.sum(axis=1)\n",
    "    df_workPark['Geo'] = df_workPark.index\n",
    "    df_parking = df_parking.merge(df_workPark[['PropWkrPay']], on=['Geo'], how = 'outer')\n",
    "    df_parking['PropWkrPay'] = df_parking['PropWkrPay'].fillna(0)\n",
    "    df_parking['Year'] = year\n",
    "    \n",
    "        \n",
    "    # PropNonWrkTripPay\n",
    "    df_trip = pd.read_csv(_join(scenpath, scenario, 'output\\indivTripData_3.csv'))\n",
    "    df_trip = df_trip[['dest_purpose', 'dest_mgra']]\n",
    "    df_joint = pd.read_csv(_join(scenpath, scenario, 'output\\jointTripData_3.csv'))\n",
    "    df_joint = df_joint[['dest_purpose', 'dest_mgra']]\n",
    "    df_trip = pd.concat([df_trip, df_joint])\n",
    "    df_trip.rename(columns={'dest_mgra':'mgra'}, inplace=True)\n",
    "    df_trip = df_trip.merge(df_mgra[['mgra','Geo']], on=['mgra'], how = 'inner') \n",
    "    df_nonworkPark = df_trip.groupby('Geo').apply(trip_agg)\n",
    "    df_nonworkPark['PropNonWrkTripPay'] = 1 - df_nonworkPark['no pay']/df_nonworkPark['all']\n",
    "    df_parking = df_parking.merge(df_nonworkPark[['PropNonWrkTripPay']], on=['Geo'], how = 'outer')\n",
    "    df_parking['PropNonWrkTripPay'] = df_parking['PropNonWrkTripPay'].fillna(0)\n",
    "    df_parking['Year'] = year    \n",
    "    \n",
    "    \n",
    "    df_parking = df_parking[['Geo', 'Year', 'PkgSpacesPerSFDU','PkgSpacesPerMFDU','PkgSpacesPerGQ','PropNonWrkTripPay', 'PropWkrPay','PropCashOut', 'PkgCost.2010']]\n",
    "    \n",
    "    if year == 2016:\n",
    "        df_parking.to_csv(_join(target_path,r'inputs\\bzone_parking.csv'), mode='w', header = True, index = False)\n",
    "    else:\n",
    "        df_parking.to_csv(_join(target_path,r'inputs\\bzone_parking.csv'), mode='a', header = False, index = False)\n",
    "    \n",
    "    print (year, 'is done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 is done\n",
      "2035 is done\n"
     ]
    }
   ],
   "source": [
    "# backup\n",
    "# PkgSpacesPerSFDU: 2, 2.5, 3, simple average if a taz contain multiple mgras with various Pseudo MSA \n",
    "# PkgSpacesPerMFDU: 1, 1.5, 3, simple average if a taz contain multiple mgras with various Pseudo MSA \n",
    "# PkgSpacesPerGQ: 0\n",
    "# PropNonWrkTripPay - Proportion of non-work trips who pay for parking\n",
    "# PropWkrPay - Proportion of workers working at jobs in the Bzone who pay for parking. Teleworkers are excluded from both numerator and demoniator\n",
    "# PropCashOut: 0\n",
    "# PkgCost.2010: simple average of mgra_mparkcost\n",
    "\n",
    "def my_agg(x):\n",
    "    names = {\n",
    "        'no praking': x[x['fp_choice']==-1]['Geo'].count(),\n",
    "        'free parking': x[x['fp_choice']==1]['Geo'].count(),\n",
    "        'paid': x[x['fp_choice']==2]['Geo'].count(),\n",
    "        'reimburse': x[x['fp_choice']==3]['Geo'].count()}\n",
    "    return pd.Series(names)\n",
    "def trip_agg(x):\n",
    "    names = {\n",
    "        'no pay': x[(x['dest_purpose']=='Escort')|(x['dest_purpose']=='Home')|(x['dest_purpose']=='Work')]['Geo'].count(),\n",
    "        'all': x['Geo'].count()}\n",
    "    return pd.Series(names)\n",
    "\n",
    "for year, scenario in scenario_list:\n",
    "    #PkgSpacesPerSFDU, PkgSpacesPerMFDU, PkgSpacesPerGQ, PkgCost.2010\n",
    "    df_parking = pd.DataFrame(list(range(13,4997,1)),columns=['Geo'])\n",
    "    df_mgra = pd.read_csv(_join(scenpath, scenario, 'input\\mgra13_based_input' + str(year) + '.csv'))\n",
    "    df_mgra.rename(columns={'taz':'Geo'}, inplace=True)  \n",
    "    df_parking = df_parking.merge(df_mgra, on=['Geo'], how = 'inner') #get TAZ pseudomsa values from mgra.file, approximation and simplification\n",
    "    df_parking = df_parking.drop_duplicates(subset =['Geo']) \n",
    "    df_parking['PkgSpacesPerSFDU'] = np.where(df_parking['pseudomsa']==1, 2, np.where(df_parking['pseudomsa']>=4,3,2.5))\n",
    "    df_parking['PkgSpacesPerMFDU'] = np.where(df_parking['pseudomsa']==1, 1, np.where(df_parking['pseudomsa']>=4,3,1.5))\n",
    "    df_parking['PkgSpacesPerGQ'] = 0\n",
    "    df_parking = df_parking[['Geo','PkgSpacesPerSFDU','PkgSpacesPerMFDU','PkgSpacesPerGQ']]\n",
    "    df_parking['PropCashOut'] = 0\n",
    "    #df_mgra['mstall'] =  df_mgra[[\"mstallsoth\", \"mstallssam\"]].max(axis=1) #weighted average parking\n",
    "    #df_mgra['mstall_park'] = df_mgra['mstall'] * df_mgra['mparkcost'] #weighted average parking\n",
    "    df_group = df_mgra.groupby('Geo', as_index=False).mean()\n",
    "    #df_group['PkgCost.2010'] = df_group['mstall_park']/df_group['mstall'] #weighted average parking\n",
    "    df_group['mparkcost'] = df_group['mparkcost'].fillna(0)\n",
    "    df_parking = df_parking.merge(df_group[['Geo', 'mparkcost']], on=['Geo'], how = 'outer')\n",
    "    df_parking.rename(columns={'mparkcost':'PkgCost.2010'}, inplace=True)\n",
    "    \n",
    "    # PropWkrPay\n",
    "    df_woc = pd.read_csv(_join(scenpath, scenario, 'output\\wsLocResults_3.csv'))\n",
    "    df_woc = df_woc[['PersonID', 'WorkLocation']]\n",
    "    df_woc.rename(columns={'PersonID':'person_id', 'WorkLocation':'mgra'}, inplace=True)\n",
    "    df_person = pd.read_csv(_join(scenpath, scenario, 'output\\personData_3.csv'))\n",
    "    df_person = df_person[['person_id','type','fp_choice']]\n",
    "    df_person = df_person.merge(df_woc, on=['person_id'], how = 'outer')\n",
    "    df_person =df_person.merge(df_mgra[['mgra','Geo']], on=['mgra'], how = 'outer')\n",
    "    df_workPark = df_person.loc[(df_person['type']=='Full-time worker') | (df_person['type']=='Part-time worker') ]\n",
    "    df_workPark = df_workPark.groupby('Geo').apply(my_agg)    \n",
    "    df_workPark['PropWkrPay'] = (df_workPark['paid'] + df_workPark['reimburse'])/df_workPark.sum(axis=1)\n",
    "    df_workPark['Geo'] = df_workPark.index\n",
    "    df_parking = df_parking.merge(df_workPark[['PropWkrPay']], on=['Geo'], how = 'outer')\n",
    "    df_parking['PropWkrPay'] = df_parking['PropWkrPay'].fillna(0)\n",
    "    df_parking['Year'] = year\n",
    "    \n",
    "        \n",
    "    # PropNonWrkTripPay\n",
    "    df_trip = pd.read_csv(_join(scenpath, scenario, 'output\\indivTripData_3.csv'))\n",
    "    df_trip = df_trip[['dest_purpose', 'dest_mgra']]\n",
    "    df_joint = pd.read_csv(_join(scenpath, scenario, 'output\\jointTripData_3.csv'))\n",
    "    df_joint = df_joint[['dest_purpose', 'dest_mgra']]\n",
    "    df_trip = pd.concat([df_trip, df_joint])\n",
    "    df_trip.rename(columns={'dest_mgra':'mgra'}, inplace=True)\n",
    "    df_trip = df_trip.merge(df_mgra[['mgra','Geo']], on=['mgra'], how = 'inner') \n",
    "    df_nonworkPark = df_trip.groupby('Geo').apply(trip_agg)\n",
    "    df_nonworkPark['PropNonWrkTripPay'] = 1 - df_nonworkPark['no pay']/df_nonworkPark['all']\n",
    "    df_parking = df_parking.merge(df_nonworkPark[['PropNonWrkTripPay']], on=['Geo'], how = 'outer')\n",
    "    df_parking['PropNonWrkTripPay'] = df_parking['PropNonWrkTripPay'].fillna(0)\n",
    "    df_parking['Year'] = year    \n",
    "    \n",
    "    \n",
    "    df_parking = df_parking[['Geo', 'Year', 'PkgSpacesPerSFDU','PkgSpacesPerMFDU','PkgSpacesPerGQ','PropNonWrkTripPay', 'PropWkrPay','PropCashOut', 'PkgCost.2010']]\n",
    "    \n",
    "    if year == 2016:\n",
    "        df_parking.to_csv(_join(target_path,r'inputs\\bzone_parking.csv'), mode='w', header = True, index = False)\n",
    "    else:\n",
    "        df_parking.to_csv(_join(target_path,r'inputs\\bzone_parking.csv'), mode='a', header = False, index = False)\n",
    "    \n",
    "    print (year, 'is done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.7 bzone_travel_demand_mgt.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign both column EcoProp and ImpProp as zero until getting updates from the planning team on the future EEO and IMP program. \n",
    "df_dmd_mgmt = pd.read_csv(_join(target_path, 'inputs', 'bzone_travel_demand_mgt.csv'))\n",
    "df_dmd_mgmt['EcoProp'] = df_dmd_mgmt['EcoProp'].fillna(0)\n",
    "df_dmd_mgmt['ImpProp'] = df_dmd_mgmt['ImpProp'].fillna(0)\n",
    "df_dmd_mgmt.to_csv(_join(target_path, 'inputs', 'bzone_travel_demand_mgt.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
